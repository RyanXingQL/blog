# 论文速览 | *DAQE: Enhancing the Quality of Compressed Images by Exploiting the Inherent Characteristic of Defocus* (TPAMI 2023)

本文简要介绍该工作的动机、方法和效果。

## 动机

图像恢复或图像质量增强任务是一个经典且实用的任务。我们课题组一直关注其中的一个子课题：编解码图像的质量增强，主要考虑到：（1）可以在图像接收端提升用户体验而不牺牲通信带宽；（2）可以降低编码端图像码率和质量，在接收端予以恢复，从而降低通信成本。

近年来深度学习网络展现出优异的性能，因此本文也聚焦于「基于深度学习的增强方法」。相关方法通常是针对整张图进行操作的，即不考虑图像内部的质量和纹理差异。考虑图像内部差异的方法不多，典型的包括：

1. 将图像空域组分分为纹理（texture）、边缘（edge）和平坦（flat/smooth）区域，然后分而治之。这是因为在统计上，前两者的增强难度比平坦区域的要大得多。
2. 学习一个增强分支决策器，让图像的不同难度的区域经过不同的增强分支。通常简单的增强分支计算复杂度也比较低。例如，[Path-Restore](https://arxiv.org/abs/1904.10343) 使用强化学习训练得到分支决策器，而 [ClassSR](https://arxiv.org/abs/2103.04039) 提出了一种难度分类损失函数。这一类方法往往会得到和上一类方法相似的结论，即增强困难区域往往是纹理区域。

个人认为，这种考虑图像内部差异的细粒度增强是大势所趋。一方面，细粒度增强可以节约计算资源，即在简单的区域简单增强；另一方面，细粒度增强可以实现更具有针对性的定制化增强，即针对不同的物体、纹理或特征分别进行增强。

同时本人也在思考，是否存在一种对「编解码图像质量增强」有帮助的图像底层特征。例如，在经典的视频插帧算法 [DAIN](https://github.com/baowenbo/DAIN) 中，作者巧妙利用了图像深度信息，使得在有遮挡的情况下插帧结果更合理。

## 图像失焦

本人最终的答案是「图像失焦」特征。这个特征具有很多好的特质：

1. 图像失焦是成像阶段固有的过程。并且，图像失焦也是一项非常成熟的渲染技术，可以被 [thin-lens model](https://en.wikipedia.org/wiki/Thin_lens) 很好地解释。
2. 经过分析，对于大部分数据集，尤其是摄影图像数据集（例如 DIV2K），其中的图像都具有非常显著的图像内失焦差异。即，图像内部不同区域的失焦程度差异较大。这种差异性可以产生很多有意思的工作。
3. 图像失焦产生了类似低通滤波器的效果。即，失焦越严重的区域，高频细节丢失得越多。在图像编解码时，这一类区域的编解码质量就相对较高（好压缩）。
4. 作为一个底层图像特征，图像失焦还在一定程度上反映了高级视觉特征，即人的注意力。因为对于摄影师而言，失焦区域往往是视觉非热点区域，聚焦区域往往是视觉热点区域。

## 方法和效果

在得到编解码图像的失焦预测信息后，本文对图像块根据失焦程度进行聚类，例如 3 类（严重失焦、中等失焦、轻度失焦）。然后，3 类图像块分别输入后续的增强网络。本文考虑了当前流行的「Transformers」和「CNNs」结构。对于 Transformers，本文让每一类图像块单独进行注意力建模；这是考虑到（1）每一类图像块的纹理差异较大，故分而治之；（2）注意力计算较慢，分开建模可以提高效率。对于 CNNs，本文扩展了 [RBQE](https://github.com/ryanxingql/rbqe) 的「提前退出」思路，即严重失焦的图像块走简单分支（因为它们的编解码质量较高），而轻度失焦的图像块走复杂分支。实验证明，考虑了失焦特征的图像质量增强在性能和效率上都具有优势。

## 局限性

本文主要的局限性如下：

1. 图像失焦特征没有 ground truth。为了解决这个问题，本文首先在训练时利用了 SOTA 的图像失焦网络来生成 ground truth；进一步，本文将得到的配对数据用于训练失焦预测子网络。为什么没有直接使用 SOTA 网络完成失焦预测？因为输入图像不是自然图像，而是编解码图像。
2. 图像失焦特征虽好，但引入了额外的计算复杂度。
